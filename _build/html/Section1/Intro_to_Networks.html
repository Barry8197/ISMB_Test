
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Graph Basics &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Section1/Intro_to_Networks';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    An Introduction to Multi Modal Analysis using Networks
                </a>
            </li>
        </ul>
        <ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../GettingStarted.html">Getting Started</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Section1_intro.html">Introduction to Network Basics</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="Part1.html"><font color="darkblue">Retrieval of Protein-Protein Interactions from STRING</font></a></li>








<li class="toctree-l2"><a class="reference internal" href="Part2.html">Section 2</a></li>







</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Section2_intro.html">Introduction to Network Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Section2/Part1.html">Section 2: Network Analysis</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../Section3_intro.html"><font color="darkblue"><u> Introduction to Graph Neural Networks </u></font></a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../Section3/Part1.html"><font color="darkblue"> Part 1 : Message Passing </font></a></li>
<li class="toctree-l2"><a class="reference internal" href="../Section3/Part2.html"><font color="darkblue"> Part 2 : Problem Formulation / Patient Similarity Network Generation </font></a></li>
<li class="toctree-l2"><a class="reference internal" href="../Section3/Part3.html"><font color="darkblue"> Part 3 : Smoking Network Classification using Graph Convolutional Networks</font></a></li>
<li class="toctree-l2"><a class="reference internal" href="../Section3/Part4.html"><font color="darkblue"> Part 4 : Similarity Network Fusion with Graph Convolutional Networks</font></a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../ConceptGlossary.html">Concept Glossary</a></li>
<li class="toctree-l1"><a class="reference internal" href="../functions_definitions.html">CUSTOM FUNCTIONS</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Barry8197/ISMB_Test" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Barry8197/ISMB_Test/issues/new?title=Issue%20on%20page%20%2FSection1/Intro_to_Networks.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Section1/Intro_to_Networks.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Graph Basics</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Graph Basics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-tensors">Working with Tensors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#node-embedding-learning">Node Embedding Learning</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="graph-basics">
<h1>Graph Basics<a class="headerlink" href="#graph-basics" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">networkx</span> <span class="k">as</span> <span class="nn">nx</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">G</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">karate_club_graph</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">type</span><span class="p">(</span><span class="n">G</span><span class="p">)</span> <span class="c1">#undirected graph</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>networkx.classes.graph.Graph
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">nx</span><span class="o">.</span><span class="n">draw</span><span class="p">(</span><span class="n">G</span> <span class="p">,</span> <span class="n">with_labels</span> <span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/51a117f20fc7d6f0d13834fbe19dbe9b9b52660a2704b5066914beae793b889c.png" src="../_images/51a117f20fc7d6f0d13834fbe19dbe9b9b52660a2704b5066914beae793b889c.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">average_degree</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">):</span>
  <span class="c1"># TODO: Implement this function that takes number of edges</span>
  <span class="c1"># and number of nodes, and returns the average node degree of </span>
  <span class="c1"># the graph. Round the result to nearest integer (for example </span>
  <span class="c1"># 3.3 will be rounded to 3 and 3.7 will be rounded to 4)</span>

  <span class="n">avg_degree</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1">############# Your code here ############</span>
  <span class="n">avg_degree</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">num_edges</span> <span class="o">/</span> <span class="n">num_nodes</span><span class="p">)</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">avg_degree</span>

<span class="n">num_edges</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_edges</span><span class="p">()</span>
<span class="n">num_nodes</span> <span class="o">=</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
<span class="n">avg_degree</span> <span class="o">=</span> <span class="n">average_degree</span><span class="p">(</span><span class="n">num_edges</span><span class="p">,</span> <span class="n">num_nodes</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average degree of karate club network is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_degree</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average degree of karate club network is 5
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">average_clustering_coefficient</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># TODO: Implement this function that takes a nx.Graph</span>
  <span class="c1"># and returns the average clustering coefficient. Round </span>
  <span class="c1"># the result to 2 decimal places (for example 3.333 will</span>
  <span class="c1"># be rounded to 3.33 and 3.7571 will be rounded to 3.76)</span>

  <span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1">############# Your code here ############</span>
  <span class="c1">## Note: </span>
  <span class="c1">## 1: Please use the appropriate NetworkX clustering function</span>
  <span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">clustering</span><span class="p">(</span><span class="n">G</span><span class="p">)</span><span class="o">.</span><span class="n">items</span><span class="p">()))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">]</span><span class="o">/</span><span class="mi">34</span> <span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">avg_cluster_coef</span>

<span class="n">avg_cluster_coef</span> <span class="o">=</span> <span class="n">average_clustering_coefficient</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Average clustering coefficient of karate club network is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">avg_cluster_coef</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Average clustering coefficient of karate club network is 0.57
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">one_iter_pagerank</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">r0</span><span class="p">,</span> <span class="n">node_id</span><span class="p">):</span>
  <span class="c1"># TODO: Implement this function that takes a nx.Graph, beta, r0 and node id.</span>
  <span class="c1"># The return value r1 is one interation PageRank value for the input node.</span>
  <span class="c1"># Please round r1 to 2 decimal places.</span>

  <span class="n">r1</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1">############# Your code here ############</span>
  <span class="c1">## Note: </span>
  <span class="c1">## 1: You should not use nx.pagerank</span>
  <span class="k">for</span> <span class="n">neighbour</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">neighbors</span><span class="p">(</span><span class="n">node_id</span><span class="p">)</span> <span class="p">:</span> 
        <span class="n">r1</span> <span class="o">+=</span> <span class="n">beta</span><span class="o">*</span><span class="p">(</span><span class="n">r0</span> <span class="o">/</span> <span class="n">G</span><span class="o">.</span><span class="n">degree</span><span class="p">[</span><span class="n">neighbour</span><span class="p">])</span> 
        
  <span class="n">r1</span> <span class="o">+=</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span> <span class="n">beta</span><span class="p">)</span><span class="o">/</span><span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
  <span class="n">r1</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">r1</span> <span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">r1</span>

<span class="n">beta</span> <span class="o">=</span> <span class="mf">0.8</span>
<span class="n">r0</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">G</span><span class="o">.</span><span class="n">number_of_nodes</span><span class="p">()</span>
<span class="n">node</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">r1</span> <span class="o">=</span> <span class="n">one_iter_pagerank</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">beta</span><span class="p">,</span> <span class="n">r0</span><span class="p">,</span> <span class="n">node</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The PageRank value for node 0 after one iteration is </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">r1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The PageRank value for node 0 after one iteration is 0.13
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
  <span class="c1"># TODO: Implement the function that calculates closeness centrality </span>
  <span class="c1"># for a node in karate club network. G is the input karate club </span>
  <span class="c1"># network and node is the node id in the graph. Please round the </span>
  <span class="c1"># closeness centrality result to 2 decimal places.</span>

  <span class="n">closeness</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="c1">## Note:</span>
  <span class="c1">## 1: You can use networkx closeness centrality function.</span>
  <span class="c1">## 2: Notice that networkx closeness centrality returns the normalized </span>
  <span class="c1">## closeness directly, which is different from the raw (unnormalized) </span>
  <span class="c1">## one that we learned in the lecture.</span>
  <span class="n">closeness</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">u</span><span class="o">=</span><span class="n">node</span><span class="p">)</span>
  <span class="n">closeness</span> <span class="o">/=</span> <span class="nb">len</span><span class="p">(</span><span class="n">nx</span><span class="o">.</span><span class="n">node_connected_component</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="p">))</span> <span class="o">-</span> <span class="mi">1</span>

  <span class="n">closeness</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">closeness</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">closeness</span>

<span class="n">node</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">closeness</span> <span class="o">=</span> <span class="n">closeness_centrality</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">node</span><span class="o">=</span><span class="n">node</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The node 5 has closeness centrality </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">closeness</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The node 5 has closeness centrality 0.02
</pre></div>
</div>
</div>
</div>
</section>
<section id="working-with-tensors">
<h1>Working with Tensors<a class="headerlink" href="#working-with-tensors" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.12.0+cu116
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">current_device</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;torch.cuda.device at 0x2a0d7e90eb0&gt;
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Generate 3 x 4 tensor with all ones</span>
<span class="n">ones</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones</span><span class="p">)</span>

<span class="c1"># Generate 3 x 4 tensor with all zeros</span>
<span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zeros</span><span class="p">)</span>

<span class="c1"># Generate 3 x 4 tensor with random values on the interval [0, 1)</span>
<span class="n">random_tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">random_tensor</span><span class="p">)</span>

<span class="c1"># Get the shape of the tensor</span>
<span class="nb">print</span><span class="p">(</span><span class="n">ones</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[1., 1., 1., 1.],
        [1., 1., 1., 1.],
        [1., 1., 1., 1.]])
tensor([[0., 0., 0., 0.],
        [0., 0., 0., 0.],
        [0., 0., 0., 0.]])
tensor([[0.8980, 0.1276, 0.8574, 0.0224],
        [0.5229, 0.4742, 0.7780, 0.4857],
        [0.3267, 0.3044, 0.6042, 0.0960]])
torch.Size([3, 4])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">zeros</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zeros</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="c1"># Change the tensor dtype to 64-bit integer</span>
<span class="n">zeros</span> <span class="o">=</span> <span class="n">zeros</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">long</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">zeros</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.float32
torch.int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">graph_to_edge_list</span><span class="p">(</span><span class="n">G</span><span class="p">):</span>
  <span class="c1"># TODO: Implement the function that returns the edge list of</span>
  <span class="c1"># an nx.Graph. The returned edge_list should be a list of tuples</span>
  <span class="c1"># where each tuple is a tuple representing an edge connected </span>
  <span class="c1"># by two nodes.</span>

  <span class="n">edge_list</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1">############# Your code here ############</span>
  <span class="n">edge_list</span> <span class="o">=</span> <span class="n">nx</span><span class="o">.</span><span class="n">edges</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">edge_list</span>

<span class="k">def</span> <span class="nf">edge_list_to_tensor</span><span class="p">(</span><span class="n">edge_list</span><span class="p">):</span>
  <span class="c1"># TODO: Implement the function that transforms the edge_list to</span>
  <span class="c1"># tensor. The input edge_list is a list of tuples and the resulting</span>
  <span class="c1"># tensor should have the shape [2 x len(edge_list)].</span>

  

  <span class="c1">############# Your code here ############</span>
  <span class="n">edge_index</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">edge_list</span><span class="p">)))</span><span class="o">.</span><span class="n">T</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">edge_index</span>

<span class="n">pos_edge_list</span> <span class="o">=</span> <span class="n">graph_to_edge_list</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="n">pos_edge_index</span> <span class="o">=</span> <span class="n">edge_list_to_tensor</span><span class="p">(</span><span class="n">pos_edge_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The pos_edge_index tensor has shape </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">pos_edge_index</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The pos_edge_index tensor has sum value </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">pos_edge_index</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The pos_edge_index tensor has shape torch.Size([2, 78])
The pos_edge_index tensor has sum value 2535
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">random</span>

<span class="k">def</span> <span class="nf">sample_negative_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="n">num_neg_samples</span><span class="p">):</span>
  <span class="c1"># TODO: Implement the function that returns a list of negative edges.</span>
  <span class="c1"># The number of sampled negative edges is num_neg_samples. You do not</span>
  <span class="c1"># need to consider the corner case when the number of possible negative edges</span>
  <span class="c1"># is less than num_neg_samples. It should be ok as long as your implementation </span>
  <span class="c1"># works on the karate club network. In this implementation, self loops should </span>
  <span class="c1"># not be considered as either a positive or negative edge. Also, notice that </span>
  <span class="c1"># the karate club network is an undirected graph, if (0, 1) is a positive </span>
  <span class="c1"># edge, do you think (1, 0) can be a negative one?</span>

    <span class="n">neg_edge_list</span> <span class="o">=</span> <span class="p">[]</span>

  <span class="c1">############# Your code here ############</span>
    <span class="n">pos_edge_list</span> <span class="o">=</span> <span class="n">graph_to_edge_list</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">node1</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
        <span class="k">for</span> <span class="n">node2</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">():</span>
            <span class="k">if</span> <span class="n">node1</span> <span class="o">&lt;</span> <span class="n">node2</span><span class="p">:</span>
                <span class="k">if</span> <span class="p">(</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">)</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">pos_edge_list</span><span class="p">:</span>
                    <span class="n">neg_edge_list</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">node1</span><span class="p">,</span> <span class="n">node2</span><span class="p">))</span>
    <span class="n">neg_edge_list</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">sample</span><span class="p">(</span><span class="n">neg_edge_list</span><span class="p">,</span> <span class="n">num_neg_samples</span><span class="p">)</span>
  <span class="c1">#########################################</span>

    <span class="k">return</span> <span class="n">neg_edge_list</span>

<span class="c1"># Sample 78 negative edges</span>
<span class="n">neg_edge_list</span> <span class="o">=</span> <span class="n">sample_negative_edges</span><span class="p">(</span><span class="n">G</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_edge_list</span><span class="p">))</span>

<span class="c1"># Transform the negative edge list to tensor</span>
<span class="n">neg_edge_index</span> <span class="o">=</span> <span class="n">edge_list_to_tensor</span><span class="p">(</span><span class="n">neg_edge_list</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The neg_edge_index tensor has shape </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">neg_edge_index</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>

<span class="c1"># Which of following edges can be negative ones?</span>
<span class="n">edge_1</span> <span class="o">=</span> <span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">edge_2</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">33</span><span class="p">)</span>
<span class="n">edge_3</span> <span class="o">=</span> <span class="p">(</span><span class="mi">33</span><span class="p">,</span> <span class="mi">22</span><span class="p">)</span>
<span class="n">edge_4</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">edge_5</span> <span class="o">=</span> <span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>

<span class="c1">############# Your code here ############</span>
<span class="c1">## Note:</span>
<span class="c1">## 1: For each of the 5 edges, print whether it can be negative edge</span>
<span class="n">pos_edge_list</span> <span class="o">=</span> <span class="n">graph_to_edge_list</span><span class="p">(</span><span class="n">G</span><span class="p">)</span>
<span class="k">for</span> <span class="n">edge</span> <span class="ow">in</span> <span class="p">[</span><span class="n">edge_1</span><span class="p">,</span> <span class="n">edge_2</span><span class="p">,</span> <span class="n">edge_3</span><span class="p">,</span> <span class="n">edge_4</span><span class="p">,</span> <span class="n">edge_5</span><span class="p">]:</span>
    <span class="k">if</span> <span class="n">edge</span> <span class="ow">in</span> <span class="n">pos_edge_list</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;No&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Yes&quot;</span><span class="p">)</span>
<span class="c1">#########################################</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>The neg_edge_index tensor has shape torch.Size([2, 78])
No
Yes
No
No
Yes
</pre></div>
</div>
</div>
</div>
</section>
<section id="node-embedding-learning">
<h1>Node Embedding Learning<a class="headerlink" href="#node-embedding-learning" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>

<span class="nb">print</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">__version__</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;frozen importlib._bootstrap&gt;:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.12.0+cu116
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize an embedding layer</span>
<span class="c1"># Suppose we want to have embedding for 4 items (e.g., nodes)</span>
<span class="c1"># Each item is represented with 8 dimensional vector</span>

<span class="n">emb_sample</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">8</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Sample embedding layer: </span><span class="si">{}</span><span class="s1">&#39;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emb_sample</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sample embedding layer: Embedding(4, 8)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select an embedding in emb_sample</span>
<span class="nb">id</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">emb_sample</span><span class="p">(</span><span class="nb">id</span><span class="p">))</span>

<span class="c1"># Select multiple embeddings</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">emb_sample</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>

<span class="c1"># Get the shape of the embedding weight matrix</span>
<span class="n">shape</span> <span class="o">=</span> <span class="n">emb_sample</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">shape</span>
<span class="nb">print</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Overwrite the weight to tensor with all ones</span>
<span class="n">emb_sample</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Let&#39;s check if the emb is indeed initilized</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">emb_sample</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>tensor([[ 0.8214, -0.6340, -0.5403, -0.9771,  0.5627, -0.6153, -1.9443, -0.2390]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
tensor([[ 0.8214, -0.6340, -0.5403, -0.9771,  0.5627, -0.6153, -1.9443, -0.2390],
        [-0.4970,  0.7978,  0.1936,  0.1587, -0.3720, -0.1713, -0.0838,  1.3219]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
torch.Size([4, 8])
tensor([[1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.],
        [1., 1., 1., 1., 1., 1., 1., 1.]], grad_fn=&lt;EmbeddingBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Please do not change / reset the random seed</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">create_node_emb</span><span class="p">(</span><span class="n">num_node</span><span class="o">=</span><span class="mi">34</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="mi">16</span><span class="p">):</span>
  <span class="c1"># TODO: Implement this function that will create the node embedding matrix.</span>
  <span class="c1"># A torch.nn.Embedding layer will be returned. You do not need to change </span>
  <span class="c1"># the values of num_node and embedding_dim. The weight matrix of returned </span>
  <span class="c1"># layer should be initialized under uniform distribution. </span>

  <span class="n">emb</span> <span class="o">=</span> <span class="kc">None</span>

  <span class="c1">############# Your code here ############</span>
  <span class="n">emb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">num_node</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">embedding_dim</span><span class="p">)</span>
  <span class="n">emb</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">num_node</span><span class="p">,</span><span class="n">embedding_dim</span><span class="p">)</span>
  <span class="c1">#########################################</span>

  <span class="k">return</span> <span class="n">emb</span>

<span class="n">emb</span> <span class="o">=</span> <span class="n">create_node_emb</span><span class="p">()</span>
<span class="n">ids</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>

<span class="c1"># Print the embedding layer</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Embedding: </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">emb</span><span class="p">))</span>

<span class="c1"># An example that gets the embeddings for node 0 and 3</span>
<span class="nb">print</span><span class="p">(</span><span class="n">emb</span><span class="p">(</span><span class="n">ids</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Embedding: Embedding(34, 16)
tensor([[0.2114, 0.7335, 0.1433, 0.9647, 0.2933, 0.7951, 0.5170, 0.2801, 0.8339,
         0.1185, 0.2355, 0.5599, 0.8966, 0.2858, 0.1955, 0.1808],
        [0.7486, 0.6546, 0.3843, 0.9820, 0.6012, 0.3710, 0.4929, 0.9915, 0.8358,
         0.4629, 0.9902, 0.7196, 0.2338, 0.0450, 0.7906, 0.9689]],
       grad_fn=&lt;EmbeddingBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">visualize_emb</span><span class="p">(</span><span class="n">emb</span><span class="p">):</span>
  <span class="n">X</span> <span class="o">=</span> <span class="n">emb</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
  <span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
  <span class="n">components</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
  <span class="n">club1_x</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">club1_y</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">club2_x</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="n">club2_y</span> <span class="o">=</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">G</span><span class="o">.</span><span class="n">nodes</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">node</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s1">&#39;club&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s1">&#39;Mr. Hi&#39;</span><span class="p">:</span>
      <span class="n">club1_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">components</span><span class="p">[</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">2</span><span class="p">])</span>
      <span class="n">club1_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">components</span><span class="p">[</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">3</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">club2_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">components</span><span class="p">[</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">2</span><span class="p">])</span>
      <span class="n">club2_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">components</span><span class="p">[</span><span class="n">node</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="mi">3</span><span class="p">])</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">club1_x</span><span class="p">,</span> <span class="n">club1_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;red&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Mr. Hi&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">club2_x</span><span class="p">,</span> <span class="n">club2_y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;blue&quot;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Officer&quot;</span><span class="p">)</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
  <span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># Visualize the initial random embeddding</span>
<span class="n">visualize_emb</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/65780380a915af0c7b637173e20f2fb275f46fece87cd4e27e88bc713a8a5cc1.png" src="../_images/65780380a915af0c7b637173e20f2fb275f46fece87cd4e27e88bc713a8a5cc1.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">def</span> <span class="nf">accuracy</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">label</span><span class="p">):</span>
    <span class="c1"># TODO: Implement the accuracy function. This function takes the </span>
    <span class="c1"># pred tensor (the resulting tensor after sigmoid) and the label </span>
    <span class="c1"># tensor (torch.LongTensor). Predicted value greater than 0.5 will </span>
    <span class="c1"># be classified as label 1. Else it will be classified as label 0.</span>
    <span class="c1"># The returned accuracy should be rounded to 4 decimal places. </span>
    <span class="c1"># For example, accuracy 0.82956 will be rounded to 0.8296.</span>

    <span class="n">accu</span> <span class="o">=</span> <span class="mf">0.0</span>

    <span class="c1">############# Your code here ############</span>
    <span class="n">accu</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">label</span><span class="p">)</span> <span class="o">==</span> <span class="n">pred</span><span class="p">)</span><span class="o">/</span><span class="nb">len</span><span class="p">(</span><span class="n">pred</span><span class="p">)</span> <span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
    <span class="c1">#########################################</span>

    <span class="k">return</span> <span class="n">accu</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">train_edge</span><span class="p">):</span>
    <span class="c1"># TODO: Train the embedding layer here. You can also change epochs and </span>
    <span class="c1"># learning rate. In general, you need to implement: </span>
    <span class="c1"># (1) Get the embeddings of the nodes in train_edge</span>
    <span class="c1"># (2) Dot product the embeddings between each node pair</span>
    <span class="c1"># (3) Feed the dot product result into sigmoid</span>
    <span class="c1"># (4) Feed the sigmoid output into the loss_fn</span>
    <span class="c1"># (5) Print both loss and accuracy of each epoch </span>
    <span class="c1"># (6) Update the embeddings using the loss and optimizer </span>
    <span class="c1"># (as a sanity check, the loss should decrease during training)</span>

    <span class="n">epochs</span> <span class="o">=</span> <span class="mi">500</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">0.1</span>

    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="n">emb</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span> <span class="n">momentum</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">epochs</span><span class="p">):</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
        <span class="n">node_emb</span> <span class="o">=</span> <span class="n">emb</span><span class="p">(</span><span class="n">train_edge</span><span class="p">)</span>
        <span class="n">dot_product</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">node_emb</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="n">node_emb</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">dot_product</span><span class="p">)</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
        <span class="n">pred</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">result</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span>
        <span class="n">accu</span> <span class="o">=</span> <span class="n">accuracy</span><span class="p">(</span><span class="n">pred</span> <span class="p">,</span> <span class="n">train_label</span><span class="p">)</span>
            
        <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Epoch:&quot;</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="s2">&quot;Loss:&quot;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> 
          <span class="s2">&quot;Acc:&quot;</span><span class="p">,</span> <span class="n">accu</span><span class="p">)</span>
        <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
        <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="c1">############# Your code here ############</span>
    <span class="c1">#########################################</span>
    <span class="k">return</span> <span class="n">emb</span>

<span class="n">loss_fn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sigmoid</span><span class="p">()</span>

<span class="nb">print</span><span class="p">(</span><span class="n">pos_edge_index</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="c1"># Generate the positive and negative labels</span>
<span class="n">pos_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">pos_edge_index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">)</span>
<span class="n">neg_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">neg_edge_index</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">)</span>

<span class="c1"># Concat positive and negative labels into one tensor</span>
<span class="n">train_label</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">neg_label</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>

<span class="c1"># Concat positive and negative edges into one tensor</span>
<span class="c1"># Since the network is very small, we do not split the edges into val/test sets</span>
<span class="n">train_edge</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">pos_edge_index</span><span class="p">,</span> <span class="n">neg_edge_index</span><span class="p">],</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">train_edge</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">emb</span> <span class="o">=</span> <span class="n">create_node_emb</span><span class="p">()</span>
<span class="n">emb</span><span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">emb</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">,</span> <span class="n">train_label</span><span class="p">,</span> <span class="n">train_edge</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>torch.Size([2, 78])
torch.Size([2, 156])
Epoch: 0 Loss: 1.9510881900787354 Acc: 0.5
Epoch: 1 Loss: 1.9377182722091675 Acc: 0.5
Epoch: 2 Loss: 1.9125335216522217 Acc: 0.5
Epoch: 3 Loss: 1.8771106004714966 Acc: 0.5
Epoch: 4 Loss: 1.833012342453003 Acc: 0.5
Epoch: 5 Loss: 1.7817574739456177 Acc: 0.5
Epoch: 6 Loss: 1.7248022556304932 Acc: 0.5
Epoch: 7 Loss: 1.6635223627090454 Acc: 0.5
Epoch: 8 Loss: 1.599200963973999 Acc: 0.5
Epoch: 9 Loss: 1.5330188274383545 Acc: 0.5
Epoch: 10 Loss: 1.4660462141036987 Acc: 0.5
Epoch: 11 Loss: 1.3992372751235962 Acc: 0.5
Epoch: 12 Loss: 1.3334225416183472 Acc: 0.5
Epoch: 13 Loss: 1.2693097591400146 Acc: 0.5
Epoch: 14 Loss: 1.2074801921844482 Acc: 0.5
Epoch: 15 Loss: 1.1483935117721558 Acc: 0.5
Epoch: 16 Loss: 1.0923917293548584 Acc: 0.5
Epoch: 17 Loss: 1.0397089719772339 Acc: 0.5
Epoch: 18 Loss: 0.9904808402061462 Acc: 0.5
Epoch: 19 Loss: 0.9447575211524963 Acc: 0.5
Epoch: 20 Loss: 0.9025160074234009 Acc: 0.5128
Epoch: 21 Loss: 0.8636741638183594 Acc: 0.5128
Epoch: 22 Loss: 0.8281030058860779 Acc: 0.5128
Epoch: 23 Loss: 0.7956387400627136 Acc: 0.5192
Epoch: 24 Loss: 0.7660935521125793 Acc: 0.5192
Epoch: 25 Loss: 0.7392647862434387 Acc: 0.5449
Epoch: 26 Loss: 0.7149428129196167 Acc: 0.5513
Epoch: 27 Loss: 0.6929178237915039 Acc: 0.5577
Epoch: 28 Loss: 0.6729835867881775 Acc: 0.5577
Epoch: 29 Loss: 0.6549423336982727 Acc: 0.5577
Epoch: 30 Loss: 0.6386069059371948 Acc: 0.5577
Epoch: 31 Loss: 0.6238017678260803 Acc: 0.5705
Epoch: 32 Loss: 0.6103647351264954 Acc: 0.5833
Epoch: 33 Loss: 0.5981468558311462 Acc: 0.5962
Epoch: 34 Loss: 0.5870124697685242 Acc: 0.6218
Epoch: 35 Loss: 0.5768385529518127 Acc: 0.641
Epoch: 36 Loss: 0.5675143003463745 Acc: 0.6538
Epoch: 37 Loss: 0.5589403510093689 Acc: 0.6667
Epoch: 38 Loss: 0.5510278344154358 Acc: 0.6731
Epoch: 39 Loss: 0.5436974763870239 Acc: 0.6859
Epoch: 40 Loss: 0.5368790030479431 Acc: 0.6987
Epoch: 41 Loss: 0.5305098295211792 Acc: 0.7051
Epoch: 42 Loss: 0.5245351195335388 Acc: 0.7051
Epoch: 43 Loss: 0.5189056396484375 Acc: 0.7179
Epoch: 44 Loss: 0.5135786533355713 Acc: 0.7372
Epoch: 45 Loss: 0.5085164308547974 Acc: 0.7436
Epoch: 46 Loss: 0.5036854147911072 Acc: 0.7692
Epoch: 47 Loss: 0.49905675649642944 Acc: 0.7692
Epoch: 48 Loss: 0.4946044385433197 Acc: 0.7821
Epoch: 49 Loss: 0.49030640721321106 Acc: 0.7949
Epoch: 50 Loss: 0.4861428737640381 Acc: 0.7949
Epoch: 51 Loss: 0.48209673166275024 Acc: 0.7949
Epoch: 52 Loss: 0.47815293073654175 Acc: 0.7949
Epoch: 53 Loss: 0.4742985665798187 Acc: 0.7949
Epoch: 54 Loss: 0.4705222249031067 Acc: 0.8013
Epoch: 55 Loss: 0.4668140411376953 Acc: 0.8141
Epoch: 56 Loss: 0.4631654918193817 Acc: 0.8205
Epoch: 57 Loss: 0.4595690369606018 Acc: 0.8205
Epoch: 58 Loss: 0.4560183882713318 Acc: 0.8269
Epoch: 59 Loss: 0.45250803232192993 Acc: 0.8269
Epoch: 60 Loss: 0.44903305172920227 Acc: 0.8333
Epoch: 61 Loss: 0.4455893635749817 Acc: 0.8397
Epoch: 62 Loss: 0.44217348098754883 Acc: 0.8397
Epoch: 63 Loss: 0.43878236413002014 Acc: 0.8526
Epoch: 64 Loss: 0.4354134500026703 Acc: 0.8718
Epoch: 65 Loss: 0.4320645332336426 Acc: 0.8718
Epoch: 66 Loss: 0.428733766078949 Acc: 0.8718
Epoch: 67 Loss: 0.4254196286201477 Acc: 0.8846
Epoch: 68 Loss: 0.4221208095550537 Acc: 0.8846
Epoch: 69 Loss: 0.41883620619773865 Acc: 0.8846
Epoch: 70 Loss: 0.41556501388549805 Acc: 0.8846
Epoch: 71 Loss: 0.41230636835098267 Acc: 0.8846
Epoch: 72 Loss: 0.4090598523616791 Acc: 0.8846
Epoch: 73 Loss: 0.4058249890804291 Acc: 0.8846
Epoch: 74 Loss: 0.402601420879364 Acc: 0.891
Epoch: 75 Loss: 0.3993888795375824 Acc: 0.891
Epoch: 76 Loss: 0.39618727564811707 Acc: 0.891
Epoch: 77 Loss: 0.39299649000167847 Acc: 0.891
Epoch: 78 Loss: 0.3898164927959442 Acc: 0.891
Epoch: 79 Loss: 0.38664737343788147 Acc: 0.891
Epoch: 80 Loss: 0.38348913192749023 Acc: 0.891
Epoch: 81 Loss: 0.3803420066833496 Acc: 0.891
Epoch: 82 Loss: 0.3772059679031372 Acc: 0.8974
Epoch: 83 Loss: 0.3740813136100769 Acc: 0.9103
Epoch: 84 Loss: 0.3709682524204254 Acc: 0.9167
Epoch: 85 Loss: 0.36786699295043945 Acc: 0.9231
Epoch: 86 Loss: 0.3647777736186981 Acc: 0.9231
Epoch: 87 Loss: 0.36170080304145813 Acc: 0.9295
Epoch: 88 Loss: 0.35863637924194336 Acc: 0.9359
Epoch: 89 Loss: 0.3555847704410553 Acc: 0.9359
Epoch: 90 Loss: 0.3525463342666626 Acc: 0.9359
Epoch: 91 Loss: 0.3495212495326996 Acc: 0.9359
Epoch: 92 Loss: 0.3465098440647125 Acc: 0.9359
Epoch: 93 Loss: 0.3435123860836029 Acc: 0.9359
Epoch: 94 Loss: 0.3405291438102722 Acc: 0.9359
Epoch: 95 Loss: 0.3375605046749115 Acc: 0.9359
Epoch: 96 Loss: 0.33460667729377747 Acc: 0.9359
Epoch: 97 Loss: 0.331667959690094 Acc: 0.9423
Epoch: 98 Loss: 0.32874464988708496 Acc: 0.9551
Epoch: 99 Loss: 0.3258369266986847 Acc: 0.9551
Epoch: 100 Loss: 0.32294517755508423 Acc: 0.9551
Epoch: 101 Loss: 0.32006964087486267 Acc: 0.9679
Epoch: 102 Loss: 0.31721052527427673 Acc: 0.9679
Epoch: 103 Loss: 0.31436803936958313 Acc: 0.9679
Epoch: 104 Loss: 0.3115425109863281 Acc: 0.9744
Epoch: 105 Loss: 0.30873411893844604 Acc: 0.9744
Epoch: 106 Loss: 0.305943101644516 Acc: 0.9744
Epoch: 107 Loss: 0.3031696379184723 Acc: 0.9808
Epoch: 108 Loss: 0.30041396617889404 Acc: 0.9808
Epoch: 109 Loss: 0.2976762056350708 Acc: 0.9808
Epoch: 110 Loss: 0.29495665431022644 Acc: 0.9808
Epoch: 111 Loss: 0.29225534200668335 Acc: 0.9808
Epoch: 112 Loss: 0.28957250714302063 Acc: 0.9808
Epoch: 113 Loss: 0.286908358335495 Acc: 0.9808
Epoch: 114 Loss: 0.28426292538642883 Acc: 0.9808
Epoch: 115 Loss: 0.28163638710975647 Acc: 0.9808
Epoch: 116 Loss: 0.27902886271476746 Acc: 0.9808
Epoch: 117 Loss: 0.27644050121307373 Acc: 0.9808
Epoch: 118 Loss: 0.2738713324069977 Acc: 0.9808
Epoch: 119 Loss: 0.27132150530815125 Acc: 0.9808
Epoch: 120 Loss: 0.2687910497188568 Acc: 0.9808
Epoch: 121 Loss: 0.2662801146507263 Acc: 0.9808
Epoch: 122 Loss: 0.26378872990608215 Acc: 0.9808
Epoch: 123 Loss: 0.2613169252872467 Acc: 0.9808
Epoch: 124 Loss: 0.25886479020118713 Acc: 0.9808
Epoch: 125 Loss: 0.2564323842525482 Acc: 0.9872
Epoch: 126 Loss: 0.25401967763900757 Acc: 0.9872
Epoch: 127 Loss: 0.25162675976753235 Acc: 0.9872
Epoch: 128 Loss: 0.24925358593463898 Acc: 0.9872
Epoch: 129 Loss: 0.24690024554729462 Acc: 0.9872
Epoch: 130 Loss: 0.24456669390201569 Acc: 0.9872
Epoch: 131 Loss: 0.2422528862953186 Acc: 0.9872
Epoch: 132 Loss: 0.2399589866399765 Acc: 1.0
Epoch: 133 Loss: 0.23768475651741028 Acc: 1.0
Epoch: 134 Loss: 0.23543037474155426 Acc: 1.0
Epoch: 135 Loss: 0.23319567739963531 Acc: 1.0
Epoch: 136 Loss: 0.2309807538986206 Acc: 1.0
Epoch: 137 Loss: 0.2287854701280594 Acc: 1.0
Epoch: 138 Loss: 0.22660984098911285 Acc: 1.0
Epoch: 139 Loss: 0.22445380687713623 Acc: 1.0
Epoch: 140 Loss: 0.22231735289096832 Acc: 1.0
Epoch: 141 Loss: 0.2202003449201584 Acc: 1.0
Epoch: 142 Loss: 0.21810282766819 Acc: 1.0
Epoch: 143 Loss: 0.21602469682693481 Acc: 1.0
Epoch: 144 Loss: 0.21396586298942566 Acc: 1.0
Epoch: 145 Loss: 0.21192629635334015 Acc: 1.0
Epoch: 146 Loss: 0.20990592241287231 Acc: 1.0
Epoch: 147 Loss: 0.2079046666622162 Acc: 1.0
Epoch: 148 Loss: 0.2059224396944046 Acc: 1.0
Epoch: 149 Loss: 0.20395921170711517 Acc: 1.0
Epoch: 150 Loss: 0.20201481878757477 Acc: 1.0
Epoch: 151 Loss: 0.2000892460346222 Acc: 1.0
Epoch: 152 Loss: 0.1981823742389679 Acc: 1.0
Epoch: 153 Loss: 0.19629409909248352 Acc: 1.0
Epoch: 154 Loss: 0.19442439079284668 Acc: 1.0
Epoch: 155 Loss: 0.19257307052612305 Acc: 1.0
Epoch: 156 Loss: 0.19074009358882904 Acc: 1.0
Epoch: 157 Loss: 0.1889253705739975 Acc: 1.0
Epoch: 158 Loss: 0.18712878227233887 Acc: 1.0
Epoch: 159 Loss: 0.1853502243757248 Acc: 1.0
Epoch: 160 Loss: 0.18358957767486572 Acc: 1.0
Epoch: 161 Loss: 0.18184678256511688 Acc: 1.0
Epoch: 162 Loss: 0.18012167513370514 Acc: 1.0
Epoch: 163 Loss: 0.17841418087482452 Acc: 1.0
Epoch: 164 Loss: 0.17672419548034668 Acc: 1.0
Epoch: 165 Loss: 0.17505158483982086 Acc: 1.0
Epoch: 166 Loss: 0.17339622974395752 Acc: 1.0
Epoch: 167 Loss: 0.1717580407857895 Acc: 1.0
Epoch: 168 Loss: 0.17013689875602722 Acc: 1.0
Epoch: 169 Loss: 0.16853265464305878 Acc: 1.0
Epoch: 170 Loss: 0.166945219039917 Acc: 1.0
Epoch: 171 Loss: 0.16537444293498993 Acc: 1.0
Epoch: 172 Loss: 0.16382023692131042 Acc: 1.0
Epoch: 173 Loss: 0.16228245198726654 Acc: 1.0
Epoch: 174 Loss: 0.1607609987258911 Acc: 1.0
Epoch: 175 Loss: 0.159255713224411 Acc: 1.0
Epoch: 176 Loss: 0.15776650607585907 Acc: 1.0
Epoch: 177 Loss: 0.15629322826862335 Acc: 1.0
Epoch: 178 Loss: 0.1548357754945755 Acc: 1.0
Epoch: 179 Loss: 0.15339398384094238 Acc: 1.0
Epoch: 180 Loss: 0.15196776390075684 Acc: 1.0
Epoch: 181 Loss: 0.15055696666240692 Acc: 1.0
Epoch: 182 Loss: 0.1491614431142807 Acc: 1.0
Epoch: 183 Loss: 0.1477811187505722 Acc: 1.0
Epoch: 184 Loss: 0.1464158147573471 Acc: 1.0
Epoch: 185 Loss: 0.14506541192531586 Acc: 1.0
Epoch: 186 Loss: 0.1437297910451889 Acc: 1.0
Epoch: 187 Loss: 0.1424088329076767 Acc: 1.0
Epoch: 188 Loss: 0.1411023736000061 Acc: 1.0
Epoch: 189 Loss: 0.13981029391288757 Acc: 1.0
Epoch: 190 Loss: 0.13853247463703156 Acc: 1.0
Epoch: 191 Loss: 0.1372687816619873 Acc: 1.0
Epoch: 192 Loss: 0.1360190361738205 Acc: 1.0
Epoch: 193 Loss: 0.13478319346904755 Acc: 1.0
Epoch: 194 Loss: 0.13356104493141174 Acc: 1.0
Epoch: 195 Loss: 0.13235250115394592 Acc: 1.0
Epoch: 196 Loss: 0.13115742802619934 Acc: 1.0
Epoch: 197 Loss: 0.12997567653656006 Acc: 1.0
Epoch: 198 Loss: 0.12880709767341614 Acc: 1.0
Epoch: 199 Loss: 0.1276516169309616 Acc: 1.0
Epoch: 200 Loss: 0.12650907039642334 Acc: 1.0
Epoch: 201 Loss: 0.12537932395935059 Acc: 1.0
Epoch: 202 Loss: 0.1242622509598732 Acc: 1.0
Epoch: 203 Loss: 0.12315770983695984 Acc: 1.0
Epoch: 204 Loss: 0.12206561863422394 Acc: 1.0
Epoch: 205 Loss: 0.12098579108715057 Acc: 1.0
Epoch: 206 Loss: 0.11991813778877258 Acc: 1.0
Epoch: 207 Loss: 0.11886249482631683 Acc: 1.0
Epoch: 208 Loss: 0.11781875789165497 Acc: 1.0
Epoch: 
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>209 Loss: 0.11678682267665863 Acc: 1.0
Epoch: 210 Loss: 0.11576652526855469 Acc: 1.0
Epoch: 211 Loss: 0.11475774645805359 Acc: 1.0
Epoch: 212 Loss: 0.11376037448644638 Acc: 1.0
Epoch: 213 Loss: 0.11277426034212112 Acc: 1.0
Epoch: 214 Loss: 0.11179932206869125 Acc: 1.0
Epoch: 215 Loss: 0.11083539575338364 Acc: 1.0
Epoch: 216 Loss: 0.10988237708806992 Acc: 1.0
Epoch: 217 Loss: 0.10894014686346054 Acc: 1.0
Epoch: 218 Loss: 0.10800857841968536 Acc: 1.0
Epoch: 219 Loss: 0.10708755254745483 Acc: 1.0
Epoch: 220 Loss: 0.1061769351363182 Acc: 1.0
Epoch: 221 Loss: 0.10527664422988892 Acc: 1.0
Epoch: 222 Loss: 0.10438653826713562 Acc: 1.0
Epoch: 223 Loss: 0.10350648313760757 Acc: 1.0
Epoch: 224 Loss: 0.1026364117860794 Acc: 1.0
Epoch: 225 Loss: 0.10177615284919739 Acc: 1.0
Epoch: 226 Loss: 0.10092563927173615 Acc: 1.0
Epoch: 227 Loss: 0.10008472204208374 Acc: 1.0
Epoch: 228 Loss: 0.09925331175327301 Acc: 1.0
Epoch: 229 Loss: 0.098431296646595 Acc: 1.0
Epoch: 230 Loss: 0.09761853516101837 Acc: 1.0
Epoch: 231 Loss: 0.09681496024131775 Acc: 1.0
Epoch: 232 Loss: 0.09602044522762299 Acc: 1.0
Epoch: 233 Loss: 0.09523487091064453 Acc: 1.0
Epoch: 234 Loss: 0.09445814043283463 Acc: 1.0
Epoch: 235 Loss: 0.0936901718378067 Acc: 1.0
Epoch: 236 Loss: 0.09293079376220703 Acc: 1.0
Epoch: 237 Loss: 0.09217998385429382 Acc: 1.0
Epoch: 238 Loss: 0.09143758565187454 Acc: 1.0
Epoch: 239 Loss: 0.09070350229740143 Acc: 1.0
Epoch: 240 Loss: 0.08997766673564911 Acc: 1.0
Epoch: 241 Loss: 0.08925992995500565 Acc: 1.0
Epoch: 242 Loss: 0.08855023235082626 Acc: 1.0
Epoch: 243 Loss: 0.08784846216440201 Acc: 1.0
Epoch: 244 Loss: 0.08715450763702393 Acc: 1.0
Epoch: 245 Loss: 0.08646830171346664 Acc: 1.0
Epoch: 246 Loss: 0.08578973263502121 Acc: 1.0
Epoch: 247 Loss: 0.08511870354413986 Acc: 1.0
Epoch: 248 Loss: 0.08445512503385544 Acc: 1.0
Epoch: 249 Loss: 0.08379890769720078 Acc: 1.0
Epoch: 250 Loss: 0.08314996212720871 Acc: 1.0
Epoch: 251 Loss: 0.08250819891691208 Acc: 1.0
Epoch: 252 Loss: 0.08187352120876312 Acc: 1.0
Epoch: 253 Loss: 0.08124583959579468 Acc: 1.0
Epoch: 254 Loss: 0.08062509447336197 Acc: 1.0
Epoch: 255 Loss: 0.08001114428043365 Acc: 1.0
Epoch: 256 Loss: 0.07940395921468735 Acc: 1.0
Epoch: 257 Loss: 0.07880342751741409 Acc: 1.0
Epoch: 258 Loss: 0.07820945978164673 Acc: 1.0
Epoch: 259 Loss: 0.07762201130390167 Acc: 1.0
Epoch: 260 Loss: 0.07704095542430878 Acc: 1.0
Epoch: 261 Loss: 0.07646623253822327 Acc: 1.0
Epoch: 262 Loss: 0.07589776068925858 Acc: 1.0
Epoch: 263 Loss: 0.07533546537160873 Acc: 1.0
Epoch: 264 Loss: 0.07477927953004837 Acc: 1.0
Epoch: 265 Loss: 0.07422909885644913 Acc: 1.0
Epoch: 266 Loss: 0.07368486374616623 Acc: 1.0
Epoch: 267 Loss: 0.0731465145945549 Acc: 1.0
Epoch: 268 Loss: 0.07261393964290619 Acc: 1.0
Epoch: 269 Loss: 0.07208709418773651 Acc: 1.0
Epoch: 270 Loss: 0.0715659037232399 Acc: 1.0
Epoch: 271 Loss: 0.07105028629302979 Acc: 1.0
Epoch: 272 Loss: 0.0705401748418808 Acc: 1.0
Epoch: 273 Loss: 0.07003550976514816 Acc: 1.0
Epoch: 274 Loss: 0.06953621655702591 Acc: 1.0
Epoch: 275 Loss: 0.06904222071170807 Acc: 1.0
Epoch: 276 Loss: 0.06855346262454987 Acc: 1.0
Epoch: 277 Loss: 0.06806988269090652 Acc: 1.0
Epoch: 278 Loss: 0.06759140640497208 Acc: 1.0
Epoch: 279 Loss: 0.06711795926094055 Acc: 1.0
Epoch: 280 Loss: 0.06664949655532837 Acc: 1.0
Epoch: 281 Loss: 0.06618595868349075 Acc: 1.0
Epoch: 282 Loss: 0.06572725623846054 Acc: 1.0
Epoch: 283 Loss: 0.06527336686849594 Acc: 1.0
Epoch: 284 Loss: 0.0648241862654686 Acc: 1.0
Epoch: 285 Loss: 0.06437969207763672 Acc: 1.0
Epoch: 286 Loss: 0.06393979489803314 Acc: 1.0
Epoch: 287 Loss: 0.06350447237491608 Acc: 1.0
Epoch: 288 Loss: 0.06307365000247955 Acc: 1.0
Epoch: 289 Loss: 0.0626472532749176 Acc: 1.0
Epoch: 290 Loss: 0.06222524493932724 Acc: 1.0
Epoch: 291 Loss: 0.06180757284164429 Acc: 1.0
Epoch: 292 Loss: 0.06139417737722397 Acc: 1.0
Epoch: 293 Loss: 0.060985010117292404 Acc: 1.0
Epoch: 294 Loss: 0.060579996556043625 Acc: 1.0
Epoch: 295 Loss: 0.06017911061644554 Acc: 1.0
Epoch: 296 Loss: 0.05978229641914368 Acc: 1.0
Epoch: 297 Loss: 0.059389498084783554 Acc: 1.0
Epoch: 298 Loss: 0.059000663459300995 Acc: 1.0
Epoch: 299 Loss: 0.05861574038863182 Acc: 1.0
Epoch: 300 Loss: 0.05823469161987305 Acc: 1.0
Epoch: 301 Loss: 0.0578574575483799 Acc: 1.0
Epoch: 302 Loss: 0.05748400464653969 Acc: 1.0
Epoch: 303 Loss: 0.057114265859127045 Acc: 1.0
Epoch: 304 Loss: 0.05674821138381958 Acc: 1.0
Epoch: 305 Loss: 0.05638579651713371 Acc: 1.0
Epoch: 306 Loss: 0.05602696165442467 Acc: 1.0
Epoch: 307 Loss: 0.055671680718660355 Acc: 1.0
Epoch: 308 Loss: 0.055319882929325104 Acc: 1.0
Epoch: 309 Loss: 0.05497156083583832 Acc: 1.0
Epoch: 310 Loss: 0.054626643657684326 Acc: 1.0
Epoch: 311 Loss: 0.05428509786725044 Acc: 1.0
Epoch: 312 Loss: 0.05394689738750458 Acc: 1.0
Epoch: 313 Loss: 0.05361197516322136 Acc: 1.0
Epoch: 314 Loss: 0.053280316293239594 Acc: 1.0
Epoch: 315 Loss: 0.05295185372233391 Acc: 1.0
Epoch: 316 Loss: 0.05262657254934311 Acc: 1.0
Epoch: 317 Loss: 0.052304428070783615 Acc: 1.0
Epoch: 318 Loss: 0.05198536068201065 Acc: 1.0
Epoch: 319 Loss: 0.05166936665773392 Acc: 1.0
Epoch: 320 Loss: 0.05135639011859894 Acc: 1.0
Epoch: 321 Loss: 0.05104639381170273 Acc: 1.0
Epoch: 322 Loss: 0.0507393442094326 Acc: 1.0
Epoch: 323 Loss: 0.05043520778417587 Acc: 1.0
Epoch: 324 Loss: 0.05013394355773926 Acc: 1.0
Epoch: 325 Loss: 0.049835529178380966 Acc: 1.0
Epoch: 326 Loss: 0.04953991621732712 Acc: 1.0
Epoch: 327 Loss: 0.04924708604812622 Acc: 1.0
Epoch: 328 Loss: 0.048956986516714096 Acc: 1.0
Epoch: 329 Loss: 0.04866960272192955 Acc: 1.0
Epoch: 330 Loss: 0.048384889960289 Acc: 1.0
Epoch: 331 Loss: 0.04810282960534096 Acc: 1.0
Epoch: 332 Loss: 0.04782336950302124 Acc: 1.0
Epoch: 333 Loss: 0.047546498477458954 Acc: 1.0
Epoch: 334 Loss: 0.047272175550460815 Acc: 1.0
Epoch: 335 Loss: 0.047000374644994736 Acc: 1.0
Epoch: 336 Loss: 0.04673106595873833 Acc: 1.0
Epoch: 337 Loss: 0.0464642159640789 Acc: 1.0
Epoch: 338 Loss: 0.046199798583984375 Acc: 1.0
Epoch: 339 Loss: 0.045937784016132355 Acc: 1.0
Epoch: 340 Loss: 0.045678142458200455 Acc: 1.0
Epoch: 341 Loss: 0.045420851558446884 Acc: 1.0
Epoch: 342 Loss: 0.04516588896512985 Acc: 1.0
Epoch: 343 Loss: 0.04491320624947548 Acc: 1.0
Epoch: 344 Loss: 0.044662803411483765 Acc: 1.0
Epoch: 345 Loss: 0.04441463202238083 Acc: 1.0
Epoch: 346 Loss: 0.04416867345571518 Acc: 1.0
Epoch: 347 Loss: 0.04392490163445473 Acc: 1.0
Epoch: 348 Loss: 0.04368329793214798 Acc: 1.0
Epoch: 349 Loss: 0.04344382882118225 Acc: 1.0
Epoch: 350 Loss: 0.04320647940039635 Acc: 1.0
Epoch: 351 Loss: 0.04297121241688728 Acc: 1.0
Epoch: 352 Loss: 0.04273800551891327 Acc: 1.0
Epoch: 353 Loss: 0.042506854981184006 Acc: 1.0
Epoch: 354 Loss: 0.04227771610021591 Acc: 1.0
Epoch: 355 Loss: 0.042050570249557495 Acc: 1.0
Epoch: 356 Loss: 0.04182539880275726 Acc: 1.0
Epoch: 357 Loss: 0.041602179408073425 Acc: 1.0
Epoch: 358 Loss: 0.04138088598847389 Acc: 1.0
Epoch: 359 Loss: 0.04116149991750717 Acc: 1.0
Epoch: 360 Loss: 0.040943995118141174 Acc: 1.0
Epoch: 361 Loss: 0.04072835296392441 Acc: 1.0
Epoch: 362 Loss: 0.04051456227898598 Acc: 1.0
Epoch: 363 Loss: 0.0403025820851326 Acc: 1.0
Epoch: 364 Loss: 0.040092408657073975 Acc: 1.0
Epoch: 365 Loss: 0.039884015917778015 Acc: 1.0
Epoch: 366 Loss: 0.03967738896608353 Acc: 1.0
Epoch: 367 Loss: 0.03947249427437782 Acc: 1.0
Epoch: 368 Loss: 0.039269331842660904 Acc: 1.0
Epoch: 369 Loss: 0.039067868143320084 Acc: 1.0
Epoch: 370 Loss: 0.03886809200048447 Acc: 1.0
Epoch: 371 Loss: 0.038669973611831665 Acc: 1.0
Epoch: 372 Loss: 0.03847351297736168 Acc: 1.0
Epoch: 373 Loss: 0.03827867656946182 Acc: 1.0
Epoch: 374 Loss: 0.0380854532122612 Acc: 1.0
Epoch: 375 Loss: 0.03789382055401802 Acc: 1.0
Epoch: 376 Loss: 0.03770375996828079 Acc: 1.0
Epoch: 377 Loss: 0.03751527518033981 Acc: 1.0
Epoch: 378 Loss: 0.0373283214867115 Acc: 1.0
Epoch: 379 Loss: 0.037142906337976456 Acc: 1.0
Epoch: 380 Loss: 0.036958981305360794 Acc: 1.0
Epoch: 381 Loss: 0.03677655756473541 Acc: 1.0
Epoch: 382 Loss: 0.03659561276435852 Acc: 1.0
Epoch: 383 Loss: 0.036416128277778625 Acc: 1.0
Epoch: 384 Loss: 0.036238089203834534 Acc: 1.0
Epoch: 385 Loss: 0.03606148436665535 Acc: 1.0
Epoch: 386 Loss: 0.03588628023862839 Acc: 1.0
Epoch: 387 Loss: 0.03571248799562454 Acc: 1.0
Epoch: 388 Loss: 0.03554007411003113 Acc: 1.0
Epoch: 389 Loss: 0.035369034856557846 Acc: 1.0
Epoch: 390 Loss: 0.035199351608753204 Acc: 1.0
Epoch: 391 Loss: 0.03503100574016571 Acc: 1.0
Epoch: 392 Loss: 0.03486398607492447 Acc: 1.0
Epoch: 393 Loss: 0.034698277711868286 Acc: 1.0
Epoch: 394 Loss: 0.03453387692570686 Acc: 1.0
Epoch: 395 Loss: 0.03437075391411781 Acc: 1.0
Epoch: 396 Loss: 0.034208908677101135 Acc: 1.0
Epoch: 397 Loss: 0.03404831886291504 Acc: 1.0
Epoch: 398 Loss: 0.03388897329568863 Acc: 1.0
Epoch: 399 Loss: 0.03373086452484131 Acc: 1.0
Epoch: 400 Loss: 0.033573977649211884 Acc: 1.0
Epoch: 401 Loss: 0.03341829404234886 Acc: 1.0
Epoch: 402 Loss: 0.03326379880309105 Acc: 1.0
Epoch: 403 Loss: 0.03311050310730934 Acc: 1.0
Epoch: 404 Loss: 0.032958365976810455 Acc: 1.0
Epoch: 405 Loss: 0.03280738741159439 Acc: 1.0
Epoch: 406 Loss: 0.03265755996108055 Acc: 1.0
Epoch: 407 Loss: 0.03250886872410774 Acc: 1.0
Epoch: 408 Loss: 0.03236129507422447 Acc: 1.0
Epoch: 409 Loss: 0.03221483901143074 Acc: 1.0
Epoch: 410 Loss: 0.032069481909275055 Acc: 1.0
Epoch: 411 Loss: 0.03192520886659622 Acc: 1.0
Epoch: 412 Loss: 0.03178202360868454 Acc: 1.0
Epoch: 413 Loss: 0.03163990005850792 Acc: 1.0
Epoch: 414 Loss: 0.03149883449077606 Acc: 1.0
Epoch: 415 Loss: 0.031358812004327774 Acc: 1.0
Epoch: 416 Loss: 0.031219836324453354 Acc: 1.0
Epoch: 417 Loss: 0.031081877648830414 Acc: 1.0
Epoch: 418 Loss: 0.030944934114813805 Acc: 1.0
Epoch: 419 Loss: 0.030809005722403526 Acc: 1.0
Epoch: 420 Loss: 0.03067406266927719 Acc: 1.0
Epoch: 421 Loss: 0.030540108680725098 Acc: 1.0
Epoch: 422 Loss: 0.03040713258087635 Acc: 1.0
Epoch: 423 Loss: 0.030275115743279457 Acc: 1.0
Epoch: 424 Loss: 0.030144061893224716 Acc: 1.0
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Epoch: 425 Loss: 0.03001396544277668 Acc: 1.0
Epoch: 426 Loss: 0.029884791001677513 Acc: 1.0
Epoch: 427 Loss: 0.02975655160844326 Acc: 1.0
Epoch: 428 Loss: 0.029629234224557877 Acc: 1.0
Epoch: 429 Loss: 0.02950282022356987 Acc: 1.0
Epoch: 430 Loss: 0.02937731333076954 Acc: 1.0
Epoch: 431 Loss: 0.029252704232931137 Acc: 1.0
Epoch: 432 Loss: 0.02912897989153862 Acc: 1.0
Epoch: 433 Loss: 0.029006119817495346 Acc: 1.0
Epoch: 434 Loss: 0.02888413891196251 Acc: 1.0
Epoch: 435 Loss: 0.02876301296055317 Acc: 1.0
Epoch: 436 Loss: 0.028642743825912476 Acc: 1.0
Epoch: 437 Loss: 0.028523312881588936 Acc: 1.0
Epoch: 438 Loss: 0.0284047182649374 Acc: 1.0
Epoch: 439 Loss: 0.028286954388022423 Acc: 1.0
Epoch: 440 Loss: 0.02817000448703766 Acc: 1.0
Epoch: 441 Loss: 0.028053876012563705 Acc: 1.0
Epoch: 442 Loss: 0.027938542887568474 Acc: 1.0
Epoch: 443 Loss: 0.02782401069998741 Acc: 1.0
Epoch: 444 Loss: 0.027710266411304474 Acc: 1.0
Epoch: 445 Loss: 0.027597304433584213 Acc: 1.0
Epoch: 446 Loss: 0.027485113590955734 Acc: 1.0
Epoch: 447 Loss: 0.027373692020773888 Acc: 1.0
Epoch: 448 Loss: 0.027263030409812927 Acc: 1.0
Epoch: 449 Loss: 0.027153128758072853 Acc: 1.0
Epoch: 450 Loss: 0.027043962851166725 Acc: 1.0
Epoch: 451 Loss: 0.026935534551739693 Acc: 1.0
Epoch: 452 Loss: 0.026827841997146606 Acc: 1.0
Epoch: 453 Loss: 0.026720885187387466 Acc: 1.0
Epoch: 454 Loss: 0.026614632457494736 Acc: 1.0
Epoch: 455 Loss: 0.026509102433919907 Acc: 1.0
Epoch: 456 Loss: 0.02640427090227604 Acc: 1.0
Epoch: 457 Loss: 0.02630014345049858 Acc: 1.0
Epoch: 458 Loss: 0.026196708902716637 Acc: 1.0
Epoch: 459 Loss: 0.02609395980834961 Acc: 1.0
Epoch: 460 Loss: 0.0259918924421072 Acc: 1.0
Epoch: 461 Loss: 0.025890493765473366 Acc: 1.0
Epoch: 462 Loss: 0.025789771229028702 Acc: 1.0
Epoch: 463 Loss: 0.025689708068966866 Acc: 1.0
Epoch: 464 Loss: 0.02559029683470726 Acc: 1.0
Epoch: 465 Loss: 0.025491541251540184 Acc: 1.0
Epoch: 466 Loss: 0.025393430143594742 Acc: 1.0
Epoch: 467 Loss: 0.025295954197645187 Acc: 1.0
Epoch: 468 Loss: 0.02519911155104637 Acc: 1.0
Epoch: 469 Loss: 0.025102905929088593 Acc: 1.0
Epoch: 470 Loss: 0.02500731125473976 Acc: 1.0
Epoch: 471 Loss: 0.024912342429161072 Acc: 1.0
Epoch: 472 Loss: 0.024817973375320435 Acc: 1.0
Epoch: 473 Loss: 0.024724217131733894 Acc: 1.0
Epoch: 474 Loss: 0.024631062522530556 Acc: 1.0
Epoch: 475 Loss: 0.024538500234484673 Acc: 1.0
Epoch: 476 Loss: 0.024446524679660797 Acc: 1.0
Epoch: 477 Loss: 0.024355143308639526 Acc: 1.0
Epoch: 478 Loss: 0.02426433190703392 Acc: 1.0
Epoch: 479 Loss: 0.024174092337489128 Acc: 1.0
Epoch: 480 Loss: 0.024084435775876045 Acc: 1.0
Epoch: 481 Loss: 0.023995336145162582 Acc: 1.0
Epoch: 482 Loss: 0.023906797170639038 Acc: 1.0
Epoch: 483 Loss: 0.023818811401724815 Acc: 1.0
Epoch: 484 Loss: 0.023731369525194168 Acc: 1.0
Epoch: 485 Loss: 0.02364448830485344 Acc: 1.0
Epoch: 486 Loss: 0.023558136075735092 Acc: 1.0
Epoch: 487 Loss: 0.02347232587635517 Acc: 1.0
Epoch: 488 Loss: 0.023387044668197632 Acc: 1.0
Epoch: 489 Loss: 0.023302294313907623 Acc: 1.0
Epoch: 490 Loss: 0.02321805991232395 Acc: 1.0
Epoch: 491 Loss: 0.023134352639317513 Acc: 1.0
Epoch: 492 Loss: 0.023051146417856216 Acc: 1.0
Epoch: 493 Loss: 0.022968458011746407 Acc: 1.0
Epoch: 494 Loss: 0.02288627438247204 Acc: 1.0
Epoch: 495 Loss: 0.022804589942097664 Acc: 1.0
Epoch: 496 Loss: 0.022723406553268433 Acc: 1.0
Epoch: 497 Loss: 0.022642707452178 Acc: 1.0
Epoch: 498 Loss: 0.022562501952052116 Acc: 1.0
Epoch: 499 Loss: 0.02248278260231018 Acc: 1.0
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">visualize_emb</span><span class="p">(</span><span class="n">emb</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/665fe64d24bc44e4f48120bc078efd0032be1cbb49dee2fb4d39e00a554b406b.png" src="../_images/665fe64d24bc44e4f48120bc078efd0032be1cbb49dee2fb4d39e00a554b406b.png" />
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Section1"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Graph Basics</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#working-with-tensors">Working with Tensors</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#node-embedding-learning">Node Embedding Learning</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The Jupyter Book Community
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
       Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>